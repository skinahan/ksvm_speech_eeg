{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "careful-legend",
   "metadata": {},
   "source": [
    "# WeightedSHAP on the EEG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-comedy",
   "metadata": {},
   "source": [
    "In this notebook, we use weightedSHAP feature attribution method to determine which features are most informative for prediction of the binary classes Read and Speak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "catholic-collection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.1 in c:\\users\\kinah\\anaconda3\\envs\\feature_selection_pca\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\kinah\\anaconda3\\envs\\feature_selection_pca\\lib\\site-packages (from pandas==1.5.1) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\kinah\\anaconda3\\envs\\feature_selection_pca\\lib\\site-packages (from pandas==1.5.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kinah\\anaconda3\\envs\\feature_selection_pca\\lib\\site-packages (from pandas==1.5.1) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kinah\\anaconda3\\envs\\feature_selection_pca\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.1) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas==1.5.1\n",
    "\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-interpretation",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hollow-export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject train_test     labels        F0        F1        F2        F3  \\\n",
      "0       CF60       test  WORD_BASS  0.000331 -0.000242  0.000033  0.000084   \n",
      "1       CF60       test   WORD_BOG  0.000338 -0.000174  0.000187  0.000090   \n",
      "2       CF60       test   WORD_BAR  0.000318  0.000161  0.000156  0.000127   \n",
      "3       CF60       test       READ  0.000349  0.000043 -0.000017  0.000005   \n",
      "4       CF60       test  WORD_BEAD  0.000327 -0.000270 -0.000057  0.000024   \n",
      "...      ...        ...        ...       ...       ...       ...       ...   \n",
      "3447    CM29      train       READ -0.007828  0.000395  0.000300  0.000199   \n",
      "3448    CM29      train       READ -0.007828  0.000395  0.000300  0.000199   \n",
      "3449    CM29      train  WORD_BATH  0.010894 -0.000039 -0.000098  0.000111   \n",
      "3450    CM29      train       READ  0.010875 -0.000102 -0.000098  0.000093   \n",
      "3451    CM29      train       READ -0.007827  0.000392  0.000289  0.000213   \n",
      "\n",
      "            F4        F5        F6  ...          F170          F171  \\\n",
      "0     0.000151  0.000139  0.000017  ... -7.045782e-07 -2.113068e-07   \n",
      "1    -0.000095 -0.000033 -0.000004  ...  4.685519e-08 -2.634985e-07   \n",
      "2     0.000240 -0.000166  0.000212  ...  5.056340e-07  1.631505e-07   \n",
      "3    -0.000003  0.000001 -0.000003  ... -1.766079e-07  1.334104e-07   \n",
      "4     0.000120 -0.000130 -0.000037  ... -9.054657e-07  3.598041e-07   \n",
      "...        ...       ...       ...  ...           ...           ...   \n",
      "3447 -0.000198 -0.000081  0.000195  ... -3.748346e-07 -1.295552e-06   \n",
      "3448 -0.000198 -0.000081  0.000195  ...  8.938746e-07  4.328543e-08   \n",
      "3449 -0.000005 -0.000139  0.000033  ...  3.378757e-07  2.345423e-07   \n",
      "3450 -0.000015 -0.000140  0.000049  ... -3.380095e-07 -3.101921e-07   \n",
      "3451 -0.000200 -0.000114  0.000208  ... -1.090038e-07 -3.073049e-07   \n",
      "\n",
      "              F172          F173          F174          F175          F176  \\\n",
      "0     2.337739e-07  3.494008e-07  1.754523e-07  3.353495e-07 -2.007851e-07   \n",
      "1    -1.290927e-07  1.932326e-08  1.081523e-07 -3.533345e-07 -5.664241e-08   \n",
      "2    -6.176892e-08 -1.373061e-07 -5.667836e-07 -1.926541e-07  4.741592e-08   \n",
      "3    -1.359630e-07  9.350540e-07 -8.317072e-08  7.617232e-08 -2.755875e-07   \n",
      "4     3.059140e-07 -1.902758e-07 -3.839111e-07  2.373410e-07  1.262268e-07   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "3447 -3.783901e-07  2.050896e-07  3.275866e-07  3.275953e-08  2.014475e-07   \n",
      "3448 -1.845036e-07 -2.873730e-07  3.964339e-08 -2.096091e-07 -7.574734e-08   \n",
      "3449  5.747163e-07  7.803253e-08 -4.252393e-07 -3.058416e-07 -4.866013e-07   \n",
      "3450  5.511527e-07  1.508799e-07 -2.704885e-08 -7.926275e-08 -1.403882e-07   \n",
      "3451 -6.505947e-08 -1.404260e-07 -3.899452e-07 -3.051679e-07  3.830273e-08   \n",
      "\n",
      "              F177          F178          F179  \n",
      "0     1.847467e-07 -2.962332e-07 -2.644030e-07  \n",
      "1    -4.506727e-07 -1.238048e-07  7.137153e-07  \n",
      "2    -1.853436e-07  6.400585e-08 -2.966773e-07  \n",
      "3     7.213996e-07  2.329804e-08  1.501049e-07  \n",
      "4    -2.768760e-07  2.673850e-07 -5.711900e-08  \n",
      "...            ...           ...           ...  \n",
      "3447  2.936416e-07  2.059824e-07  4.035992e-07  \n",
      "3448 -1.807965e-07  4.171624e-07  1.574215e-07  \n",
      "3449 -2.235345e-07  4.143266e-08  1.169003e-07  \n",
      "3450 -3.951446e-07 -1.998287e-08  4.874709e-07  \n",
      "3451 -6.394128e-07  2.145251e-07 -3.208671e-07  \n",
      "\n",
      "[3452 rows x 183 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('../eeg_dataset.pkl')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-cookbook",
   "metadata": {},
   "source": [
    "## We will now split the dataset into train, val, est, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "artificial-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weightedSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-slovakia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for training a surrogate model: 14.58 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/49 [00:00<?, ?it/s]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0519176483168087\n",
      "Total number of random sets: 300, GR_stat: 1.03052441506388\n",
      "Total number of random sets: 400, GR_stat: 1.0180687799266361\n",
      "Total number of random sets: 500, GR_stat: 1.0308962365809942\n",
      "Total number of random sets: 600, GR_stat: 1.0126624737275611\n",
      "Total number of random sets: 700, GR_stat: 1.0099584960472079\n",
      "Total number of random sets: 800, GR_stat: 1.0124462180458087\n",
      "Total number of random sets: 900, GR_stat: 1.0101696846747243\n",
      "Total number of random sets: 1000, GR_stat: 1.0109577092508033\n",
      "Total number of random sets: 1100, GR_stat: 1.0083569753985577\n",
      "Total number of random sets: 1200, GR_stat: 1.0104025034046982\n",
      "Total number of random sets: 1300, GR_stat: 1.0083584812976214\n",
      "Total number of random sets: 1400, GR_stat: 1.0077709102186847\n",
      "Total number of random sets: 1500, GR_stat: 1.0057143665420596\n",
      "Total number of random sets: 1600, GR_stat: 1.0043506021238449\n",
      "Therehosld: 17982\n",
      "We have seen 1700 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                 | 1/49 [01:02<50:21, 62.94s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0334566973440984\n",
      "Total number of random sets: 300, GR_stat: 1.0316911900421741\n",
      "Total number of random sets: 400, GR_stat: 1.0245169214042817\n",
      "Total number of random sets: 500, GR_stat: 1.0166815717869575\n",
      "Total number of random sets: 600, GR_stat: 1.0156415955039557\n",
      "Total number of random sets: 700, GR_stat: 1.0139871466006347\n",
      "Total number of random sets: 800, GR_stat: 1.0112438530437728\n",
      "Total number of random sets: 900, GR_stat: 1.014034306036496\n",
      "Total number of random sets: 1000, GR_stat: 1.0087343343051578\n",
      "Total number of random sets: 1100, GR_stat: 1.006878374364216\n",
      "Total number of random sets: 1200, GR_stat: 1.0107319022490104\n",
      "Total number of random sets: 1300, GR_stat: 1.0056131082514161\n",
      "Total number of random sets: 1400, GR_stat: 1.0068430154387145\n",
      "Total number of random sets: 1500, GR_stat: 1.006082883460184\n",
      "Total number of random sets: 1600, GR_stat: 1.0074599842108274\n",
      "Total number of random sets: 1700, GR_stat: 1.0045625104210314\n",
      "Therehosld: 17982\n",
      "We have seen 1800 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                               | 2/49 [02:09<50:58, 65.08s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.051299791950762\n",
      "Total number of random sets: 300, GR_stat: 1.0282104657051427\n",
      "Total number of random sets: 400, GR_stat: 1.0194696646592145\n",
      "Total number of random sets: 500, GR_stat: 1.0287588270703216\n",
      "Total number of random sets: 600, GR_stat: 1.0180336527768956\n",
      "Total number of random sets: 700, GR_stat: 1.008676052573093\n",
      "Total number of random sets: 800, GR_stat: 1.0093567837744055\n",
      "Total number of random sets: 900, GR_stat: 1.0118620776033205\n",
      "Total number of random sets: 1000, GR_stat: 1.0099675125955474\n",
      "Total number of random sets: 1100, GR_stat: 1.0092586860536505\n",
      "Total number of random sets: 1200, GR_stat: 1.0053827151917623\n",
      "Total number of random sets: 1300, GR_stat: 1.0070315559295842\n",
      "Total number of random sets: 1400, GR_stat: 1.0065817104575419\n",
      "Total number of random sets: 1500, GR_stat: 1.0051946086146835\n",
      "Total number of random sets: 1600, GR_stat: 1.0043505121143939\n",
      "Therehosld: 17982\n",
      "We have seen 1700 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                              | 3/49 [03:12<49:00, 63.93s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0369111163410978\n",
      "Total number of random sets: 300, GR_stat: 1.023885106480971\n",
      "Total number of random sets: 400, GR_stat: 1.0172107268235526\n",
      "Total number of random sets: 500, GR_stat: 1.0128307396001095\n",
      "Total number of random sets: 600, GR_stat: 1.0110187156350547\n",
      "Total number of random sets: 700, GR_stat: 1.0098963339612061\n",
      "Total number of random sets: 800, GR_stat: 1.0070159252299458\n",
      "Total number of random sets: 900, GR_stat: 1.0066331483720958\n",
      "Total number of random sets: 1000, GR_stat: 1.007544011809485\n",
      "Total number of random sets: 1100, GR_stat: 1.00784057738517\n",
      "Total number of random sets: 1200, GR_stat: 1.0067772425992145\n",
      "Total number of random sets: 1300, GR_stat: 1.006467493858842\n",
      "Total number of random sets: 1400, GR_stat: 1.0063147208245902\n",
      "Total number of random sets: 1500, GR_stat: 1.0065081399062048\n",
      "Total number of random sets: 1600, GR_stat: 1.0084734733945566\n",
      "Total number of random sets: 1700, GR_stat: 1.0058123072743097\n",
      "Total number of random sets: 1800, GR_stat: 1.005810826915147\n",
      "Total number of random sets: 1900, GR_stat: 1.004966617152417\n",
      "Therehosld: 17982\n",
      "We have seen 2000 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▊                                                                            | 4/49 [04:26<51:00, 68.01s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.062917966060532\n",
      "Total number of random sets: 300, GR_stat: 1.0342190176756851\n",
      "Total number of random sets: 400, GR_stat: 1.0167600566606732\n",
      "Total number of random sets: 500, GR_stat: 1.0202233617427123\n",
      "Total number of random sets: 600, GR_stat: 1.014766867708206\n",
      "Total number of random sets: 700, GR_stat: 1.0120042948946657\n",
      "Total number of random sets: 800, GR_stat: 1.0080595811488249\n",
      "Total number of random sets: 900, GR_stat: 1.0105332577994444\n",
      "Total number of random sets: 1000, GR_stat: 1.0093763125601982\n",
      "Total number of random sets: 1100, GR_stat: 1.0083074114043433\n",
      "Total number of random sets: 1200, GR_stat: 1.0093070132600523\n",
      "Total number of random sets: 1300, GR_stat: 1.0111324146810394\n",
      "Total number of random sets: 1400, GR_stat: 1.0083817648262072\n",
      "Total number of random sets: 1500, GR_stat: 1.0079661061880831\n",
      "Total number of random sets: 1600, GR_stat: 1.0053690369166306\n",
      "Total number of random sets: 1700, GR_stat: 1.006325764977977\n",
      "Total number of random sets: 1800, GR_stat: 1.0059924702411964\n",
      "Total number of random sets: 1900, GR_stat: 1.0079266756534413\n",
      "Total number of random sets: 2000, GR_stat: 1.005006404179091\n",
      "Total number of random sets: 2100, GR_stat: 1.0051649643777203\n",
      "Total number of random sets: 2200, GR_stat: 1.0040514954985509\n",
      "Therehosld: 17982\n",
      "We have seen 2300 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                          | 5/49 [05:52<54:44, 74.64s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0431416568831196\n",
      "Total number of random sets: 300, GR_stat: 1.0388543832938024\n",
      "Total number of random sets: 400, GR_stat: 1.0160472587558582\n",
      "Total number of random sets: 500, GR_stat: 1.0155417915827623\n",
      "Total number of random sets: 600, GR_stat: 1.0120887982688056\n",
      "Total number of random sets: 700, GR_stat: 1.0117377595496968\n",
      "Total number of random sets: 800, GR_stat: 1.0133775943349101\n",
      "Total number of random sets: 900, GR_stat: 1.0081531691445524\n",
      "Total number of random sets: 1000, GR_stat: 1.0084163104307402\n",
      "Total number of random sets: 1100, GR_stat: 1.0106016977899503\n",
      "Total number of random sets: 1200, GR_stat: 1.0077569337482852\n",
      "Total number of random sets: 1300, GR_stat: 1.0060792118269157\n",
      "Total number of random sets: 1400, GR_stat: 1.004846157796246\n",
      "Therehosld: 17982\n",
      "We have seen 1500 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▏                                                                        | 6/49 [06:47<48:40, 67.92s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0345782701444544\n",
      "Total number of random sets: 300, GR_stat: 1.0288086026899885\n",
      "Total number of random sets: 400, GR_stat: 1.0259474532683146\n",
      "Total number of random sets: 500, GR_stat: 1.0194575303675377\n",
      "Total number of random sets: 600, GR_stat: 1.0167930752405048\n",
      "Total number of random sets: 700, GR_stat: 1.0136472905555052\n",
      "Total number of random sets: 800, GR_stat: 1.0106661567669581\n",
      "Total number of random sets: 900, GR_stat: 1.0090940606748686\n",
      "Total number of random sets: 1000, GR_stat: 1.0065507980487394\n",
      "Total number of random sets: 1100, GR_stat: 1.0077392142525867\n",
      "Total number of random sets: 1200, GR_stat: 1.0076826954450406\n",
      "Total number of random sets: 1300, GR_stat: 1.0096060007204413\n",
      "Total number of random sets: 1400, GR_stat: 1.0062879513433827\n",
      "Total number of random sets: 1500, GR_stat: 1.009081356797844\n",
      "Total number of random sets: 1600, GR_stat: 1.006982486698088\n",
      "Total number of random sets: 1700, GR_stat: 1.0048080009754572\n",
      "Therehosld: 17982\n",
      "We have seen 1800 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▊                                                                       | 7/49 [07:53<47:10, 67.39s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0387274146632044\n",
      "Total number of random sets: 300, GR_stat: 1.0222136349229287\n",
      "Total number of random sets: 400, GR_stat: 1.019510189572663\n",
      "Total number of random sets: 500, GR_stat: 1.0119685231731461\n",
      "Total number of random sets: 600, GR_stat: 1.0181684695446631\n",
      "Total number of random sets: 700, GR_stat: 1.0119365365821975\n",
      "Total number of random sets: 800, GR_stat: 1.0093277061135875\n",
      "Total number of random sets: 900, GR_stat: 1.0108412476150885\n",
      "Total number of random sets: 1000, GR_stat: 1.0073192777390618\n",
      "Total number of random sets: 1100, GR_stat: 1.0090025692674918\n",
      "Total number of random sets: 1200, GR_stat: 1.0075149981505975\n",
      "Total number of random sets: 1300, GR_stat: 1.0082627855101163\n",
      "Total number of random sets: 1400, GR_stat: 1.0059423774031955\n",
      "Total number of random sets: 1500, GR_stat: 1.0056446530384353\n",
      "Total number of random sets: 1600, GR_stat: 1.0051771370141318\n",
      "Total number of random sets: 1700, GR_stat: 1.0058557096374907\n",
      "Total number of random sets: 1800, GR_stat: 1.0052786823408737\n",
      "Total number of random sets: 1900, GR_stat: 1.0039742991404719\n",
      "Therehosld: 17982\n",
      "We have seen 2000 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▌                                                                     | 8/49 [09:07<47:28, 69.46s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.037381756450761\n",
      "Total number of random sets: 300, GR_stat: 1.0374229970159572\n",
      "Total number of random sets: 400, GR_stat: 1.0318820729930323\n",
      "Total number of random sets: 500, GR_stat: 1.0225074782600574\n",
      "Total number of random sets: 600, GR_stat: 1.0148426829346098\n",
      "Total number of random sets: 700, GR_stat: 1.0133309448679784\n",
      "Total number of random sets: 800, GR_stat: 1.0124146321545924\n",
      "Total number of random sets: 900, GR_stat: 1.009013904006124\n",
      "Total number of random sets: 1000, GR_stat: 1.0086379226412272\n",
      "Total number of random sets: 1100, GR_stat: 1.0077581051553894\n",
      "Total number of random sets: 1200, GR_stat: 1.0080018760324152\n",
      "Total number of random sets: 1300, GR_stat: 1.0080239305621923\n",
      "Total number of random sets: 1400, GR_stat: 1.0065789024878102\n",
      "Total number of random sets: 1500, GR_stat: 1.0067465706292291\n",
      "Total number of random sets: 1600, GR_stat: 1.0059706567198177\n",
      "Total number of random sets: 1700, GR_stat: 1.0074011996327084\n",
      "Total number of random sets: 1800, GR_stat: 1.0041800098653917\n",
      "Therehosld: 17982\n",
      "We have seen 1900 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▏                                                                   | 9/49 [10:18<46:30, 69.77s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0436695965478107\n",
      "Total number of random sets: 300, GR_stat: 1.0294509706222297\n",
      "Total number of random sets: 400, GR_stat: 1.0246236167268719\n",
      "Total number of random sets: 500, GR_stat: 1.0221544827592\n",
      "Total number of random sets: 600, GR_stat: 1.0145885888793178\n",
      "Total number of random sets: 700, GR_stat: 1.011716329664492\n",
      "Total number of random sets: 800, GR_stat: 1.0115048753094438\n",
      "Total number of random sets: 900, GR_stat: 1.009440068715953\n",
      "Total number of random sets: 1000, GR_stat: 1.01013114200031\n",
      "Total number of random sets: 1100, GR_stat: 1.0064870446539629\n",
      "Total number of random sets: 1200, GR_stat: 1.0070785544474627\n",
      "Total number of random sets: 1300, GR_stat: 1.0081033233353869\n",
      "Total number of random sets: 1400, GR_stat: 1.0068593245440685\n",
      "Total number of random sets: 1500, GR_stat: 1.0061481412326647\n",
      "Total number of random sets: 1600, GR_stat: 1.0056210389564055\n",
      "Total number of random sets: 1700, GR_stat: 1.0048478589915562\n",
      "Therehosld: 17982\n",
      "We have seen 1800 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▋                                                                 | 10/49 [11:24<44:41, 68.75s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.068498385970198\n",
      "Total number of random sets: 300, GR_stat: 1.0287271228228294\n",
      "Total number of random sets: 400, GR_stat: 1.0195145506176402\n",
      "Total number of random sets: 500, GR_stat: 1.0229980535766179\n",
      "Total number of random sets: 600, GR_stat: 1.0162598668761837\n",
      "Total number of random sets: 700, GR_stat: 1.0102421540852342\n",
      "Total number of random sets: 800, GR_stat: 1.0091880245029292\n",
      "Total number of random sets: 900, GR_stat: 1.0101618017495666\n",
      "Total number of random sets: 1000, GR_stat: 1.007218776549582\n",
      "Total number of random sets: 1100, GR_stat: 1.0062617421024016\n",
      "Total number of random sets: 1200, GR_stat: 1.0060467818450431\n",
      "Total number of random sets: 1300, GR_stat: 1.0076333065614185\n",
      "Total number of random sets: 1400, GR_stat: 1.007375906118512\n",
      "Total number of random sets: 1500, GR_stat: 1.004981534232028\n",
      "Therehosld: 17982\n",
      "We have seen 1600 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▍                                                               | 11/49 [12:23<41:36, 65.71s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.044201618700027\n",
      "Total number of random sets: 300, GR_stat: 1.0369610140656869\n",
      "Total number of random sets: 400, GR_stat: 1.0194746740614624\n",
      "Total number of random sets: 500, GR_stat: 1.0149158320606193\n",
      "Total number of random sets: 600, GR_stat: 1.0113737514444203\n",
      "Total number of random sets: 700, GR_stat: 1.0119037656224186\n",
      "Total number of random sets: 800, GR_stat: 1.0090001157237958\n",
      "Total number of random sets: 900, GR_stat: 1.0074565625787768\n",
      "Total number of random sets: 1000, GR_stat: 1.0074719732315705\n",
      "Total number of random sets: 1100, GR_stat: 1.00748514482312\n",
      "Total number of random sets: 1200, GR_stat: 1.0050620338490397\n",
      "Total number of random sets: 1300, GR_stat: 1.0056020800359864\n",
      "Total number of random sets: 1400, GR_stat: 1.004665139692604\n",
      "Therehosld: 17982\n",
      "We have seen 1500 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████                                                              | 12/49 [13:18<38:30, 62.45s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0472020571811813\n",
      "Total number of random sets: 300, GR_stat: 1.0266778139078196\n",
      "Total number of random sets: 400, GR_stat: 1.0207717312625535\n",
      "Total number of random sets: 500, GR_stat: 1.018852911166702\n",
      "Total number of random sets: 600, GR_stat: 1.0118929473957088\n",
      "Total number of random sets: 700, GR_stat: 1.0152679089047238\n",
      "Total number of random sets: 800, GR_stat: 1.009942250499335\n",
      "Total number of random sets: 900, GR_stat: 1.0113128960300213\n",
      "Total number of random sets: 1000, GR_stat: 1.0103997248790837\n",
      "Total number of random sets: 1100, GR_stat: 1.0093136682576558\n",
      "Total number of random sets: 1200, GR_stat: 1.0071191342365913\n",
      "Total number of random sets: 1300, GR_stat: 1.0080474348796173\n",
      "Total number of random sets: 1400, GR_stat: 1.008292074939134\n",
      "Total number of random sets: 1500, GR_stat: 1.0076393425166128\n",
      "Total number of random sets: 1600, GR_stat: 1.0040426886511165\n",
      "Therehosld: 17982\n",
      "We have seen 1700 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▊                                                            | 13/49 [14:21<37:33, 62.60s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0568420073223777\n",
      "Total number of random sets: 300, GR_stat: 1.029132300043103\n",
      "Total number of random sets: 400, GR_stat: 1.0237186234107774\n",
      "Total number of random sets: 500, GR_stat: 1.0164021641889887\n",
      "Total number of random sets: 600, GR_stat: 1.0160524675028881\n",
      "Total number of random sets: 700, GR_stat: 1.0115316180499683\n",
      "Total number of random sets: 800, GR_stat: 1.012249417878942\n",
      "Total number of random sets: 900, GR_stat: 1.0106649036258544\n",
      "Total number of random sets: 1000, GR_stat: 1.0079813339102865\n",
      "Total number of random sets: 1100, GR_stat: 1.0077861431366215\n",
      "Total number of random sets: 1200, GR_stat: 1.0088677301893438\n",
      "Total number of random sets: 1300, GR_stat: 1.0085909782489677\n",
      "Total number of random sets: 1400, GR_stat: 1.0048090225965216\n",
      "Therehosld: 17982\n",
      "We have seen 1500 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▍                                                          | 14/49 [15:16<35:06, 60.18s/it]C:\\Users\\Kinah\\repos\\ksvm_speech_eeg\\notebook\\..\\weightedSHAP\\train.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_condi_wrapper = lambda x, S: surrogate_model((torch.tensor(x, dtype=torch.float32, device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 200, GR_stat: 1.0491306758970473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "debug = True\n",
    "train_all = df[df[\"train_test\"] == \"train\"]\n",
    "test_all = df[df[\"train_test\"] == \"test\"]\n",
    "\n",
    "subj_list = np.unique(df[\"subject\"])\n",
    "\n",
    "for test_subj in subj_list:\n",
    "    # train_subjs = [subj for subj in subj_list if subj != test_subj]\n",
    "    # Use the held-out subject for test (and validation??)\n",
    "    held_data = df[df[\"subject\"] == test_subj]\n",
    "    test = held_data[held_data[\"train_test\"] == \"test\"]\n",
    "    \n",
    "    # Use all other subjects for train\n",
    "    train_data = df[df[\"subject\"] != test_subj]\n",
    "    train_all = train_data[train_data[\"train_test\"] != \"test\"]\n",
    "    \n",
    "    train, est = train_test_split(train_all, test_size = 0.2)\n",
    "    est, val = train_test_split(est, test_size = 0.5)\n",
    "    # Have: train, est, val, and test\n",
    "    \n",
    "    # Need: X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    \n",
    "    # select only the features\n",
    "    X_train = train.iloc[:, 3:184]\n",
    "    X_est = est.iloc[:, 3:184]\n",
    "    X_val = val.iloc[:, 3:184] \n",
    "    X_test = test.iloc[:, 3:184]\n",
    "    \n",
    "    y_train = [0 if i == \"READ\" else 1 for i in train[\"labels\"]]\n",
    "    y_est = [0 if i == \"READ\" else 1 for i in est[\"labels\"]]\n",
    "    y_val = [0 if i == \"READ\" else 1 for i in val[\"labels\"]]\n",
    "    y_test = [0 if i == \"READ\" else 1 for i in test[\"labels\"]]\n",
    "    \n",
    "    X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    X_est = torch.tensor(X_est.values, dtype=torch.float32)\n",
    "    X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    X_test= torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    \n",
    "    y_train = torch.tensor(y_train)\n",
    "    y_est = torch.tensor(y_est)\n",
    "    y_val = torch.tensor(y_val)\n",
    "    y_test = torch.tensor(y_test)\n",
    "    \n",
    "    # Have: X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    \n",
    "    # Create the model\n",
    "    svc = SVC(kernel='rbf', C = 1.0, class_weight='balanced')\n",
    "    # Train the model\n",
    "    svc.fit(X_train, y_train)\n",
    "    # Generate a conditional coalition function\n",
    "    conditional_extension = weightedSHAP.generate_coalition_function(svc, X_train, X_est, 'classification', 'eeg')\n",
    "    \n",
    "    # With the conditional coalition function, compute attributions\n",
    "    exp_dict = weightedSHAP.compute_attributions('classification', 'eeg',\n",
    "                                                 svc, conditional_extension,\n",
    "                                                 X_train, y_train,\n",
    "                                                 X_val, y_val,\n",
    "                                                 X_test, y_test)\n",
    "    \n",
    "    print(exp_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
